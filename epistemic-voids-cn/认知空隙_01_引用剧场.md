---
title: "认知空隙 #1: 引用剧场"
subtitle: "当论文变成道具"
authors:
  - "林徐乐"
  - "Claude"
keywords:
  - 认知空隙
  - 引用剧场
  - AI工作流
  - 学术写作
  - 认识论责任
  - 质性研究
link: https://www.threadcounts.org/p/epistemic-voids-1-citation-theater
date: 2025-11-30
---

# 认知空隙 #1: 引用剧场

## 当论文变成道具

## 那条帖子

昨天X上一条帖子火了（400万浏览）。等我刷到时，评论风向已变：感激逐渐发酸变成质疑，某人的导师在一条回复里话说到一半停住了。

"我一个下午写了4000字论文。"

后来作者删了帖。但那张工作流示意图早已被保存、转发。内容是这样的：

> 我一个下午写了4000字论文——
>
> 方法如下，外加两个神奇提示词（放心，合乎伦理！）：
>
> **1: 收集你写过的任何东西**
> → 上传你的旧论文、草稿或研究笔记。
> → 什么都没有？上传一篇你领域内别人的论文。
> → 最坏情况：写个你预想中论文的粗略大纲。
>
> **2: 确定叙事主线**
> → 让ChatGPT为每段写一个五字短句。
> → 这些是概括每段的占位符。
> → 调整、重排这些句子，直到通篇叙事从头到尾说得通。
> → 你掌控叙事——不是AI。
>
> **3: 将每句话扩展成一系列观点**
> → 用ChatGPT将每个句子转化为段落大纲，结构如下：
>   → 1个主题句
>   → 2–4个支撑观点
>   → 1个总结句
> → 这些只是通用想法，除非你的话题极其小众，否则效果极佳。
> → 这样你就有了一份自洽且逻辑严密的蓝图。
>
> **4: 加入真实研究**
> → 把每个观点句喂给Consensus。
> → 工具轻松为每段找到10篇好论文。
> → 略读并提取关键事实。
> → 目标是浓缩成原子句，比如："吸烟致癌"（Smith, 2020）。
> → 现在你有了一组真实的、有文献支撑的笔记。
>
> **5: 起草正文段落**
> → 把这些事实笔记喂给ChatGPT。
> → 生成干净、带引用的学术段落。
> → 每段重复此操作。
> → 现在你有了完整的初稿：结构清晰、有据可查、可读性强。
>
> 这个流程消灭空白页焦虑。它让你在写出任何真实段落前就看到全貌。不用再猜了。你在建造。
>
> **这样做合乎伦理吗？**
> 我觉得是的，因为AI只是帮我组织和表达观点。我掌控叙事、决定说什么——AI只是帮我把话说清楚。它把我的论文、笔记和大纲转化为被接受的学术写作形式。每一步都经过事实核查，最终成果仍是100%我的智力产出。

![EffortlessAcademic工作流信息图](attachments/epistemic_voids_01_citation_theater_01_effortlessacademic.jpeg)

乍看像是有人终于破解了论文写作的混沌。方框，箭头，步骤。

凑近看。

---

## 颠倒

我把那张图读了三遍。两个短语格外刺眼：

"利用ChatGPT的**通用知识**生成内容**观点**。"

"把论文当作**你观点的证据**。"

先产生观点，再去搜罗证据——这意味着什么？

构成论文的实际主张源自ChatGPT的通用知识——模型读过的关于这个话题所有内容的统计平均值。没有深度阅读。没有在文献矛盾中挣扎。

提示词2说得很直白："参考上传的论文把握研究的整体方向……然后运用**你自己**关于生态学和气候变化的**知识**，为每段提出有效观点。"

这条流水线是倒着转的：

> AI生成主张 → 搜索证据

而非

> 证据 → 主张

AI生成观点。AI生成结构。*然后*你（用Consensus、Elicit这类工具）去搜捕论文来"充当证据"：论文被事后改装以支撑早已成型的主张，像选好了套装再去配饰品。

所以当作者声称"100%我的智力产出"时，智力劳动在哪里？

这颠倒了真正产生理解的顺序。

主张本该在后。首先是：一个让你着迷的现象，一段让你困惑的阅读。矛盾浮现。证据冲突。角力随之而来。一个立场逐渐显形，试探但可辩护，因为你见过什么能推翻它。

这种挣扎感觉像低效。认知恰恰发生于此。

在这里，论文不是基石。是装饰。

在我看来，问题在于：对你并未真正完成的工作宣示智力主权。

这就是**引用剧场**（citation theater）。我们都见过——先有主张再回填引用的工作。这个工作流把这种做法自动化了，再包装成创新卖回来。

---

## 缺失的东西

顺着那五个步骤往下看。哪一步让你去自找麻烦？

- 什么证据会*挑战*这个主张？
- 存在哪些替代解释？
- 哪些论文彼此*冲突*？

没有。

整个架构完全是确认性的。反面证据不可见。流程图确实包含一个反馈环："让ChatGPT诚实批评。"但凑近看——它批评的是*叙事*，不是事实。连自我修正都是关于表演的。

诱惑在于它*感觉*很勤奋。每段都有多处引用。你确实打开了PDF。参考文献列表很长。但你在表演学术的可见仪式，却把真正的判断外包给了一个对你的主张能否经受检验毫无利害关系的模型。

---

## 建议背后的生意

这不是同行在分享工作流。作者经营着一家向学者兜售AI生产力课程的公司，数万粉丝，那条爆款帖子是营销。

"100%我的智力产出"作为销售话术，听起来味道就不一样了。研究者正成为这类建议的*靶子*——包装成生产力技巧，当作课程售卖。

删帖这件事因此意味深长。连卖家自己都动摇了。

当生产力建议来自有东西要卖的人，问题就变了：谁从我相信这套有效中获益？

---

## 对照

如果架构本身就要求严谨呢？

谷歌的**AI协同科学家**（AI Co-Scientist）是基于Gemini 2.0构建的多智能体系统。美学风格和那张爆款论文图表一致：方框，箭头，智能体，反馈环。

![Google AI协同科学家系统图](attachments/epistemic_voids_01_citation_theater_02_aicoscientist_overview.png)

认识论完全不同。

系统使用一组受科学方法启发的专业智能体联盟：

- **生成智能体**：探索文献，运行*模拟科学辩论*以产生候选假设
- **反思智能体**：充当挑剔的同行评审，评估合理性、新颖性、可检验性
- **排序智能体**：基于Elo评分的锦标赛，假设两两对决，弱点暴露无遗
- **演化智能体**：迭代改进排名靠前的假设，解决局限
- **元评审智能体**：综合反馈，生成研究综述

生成 → 辩论 → 排序 → 演化 → 评审。循环往复。系统在与自己争论。经不起内部批评的假设，在人类看到之前就被淘汰了。

几位科学家和谷歌团队在实际实验室实验中验证了系统输出：针对急性髓系白血病的药物再利用候选物，后经*体外*实验证实。另一项测试中，AI独立重新发现了研究人员已找到但尚未发表的一个机制。

在诠释性研究中，"验证"看起来不同：负面案例分析、独立编码、同行批评。方法各异。原则不变。主张必须经受可能证明其错误或不足的审视。

协同科学家让AI*赢得*它的结论。

---

## 中空的核心

把它们并排放在一起。

人类与文献的深度互动产生真正的理解。你能为自己的主张辩护。你知道薄弱点在哪。

带有对抗性审查的严谨AI系统产生经受住内部批评的输出。AI完成了真正的认知劳动。

那个爆款工作流两者都不是。人类为了确认而略读。AI在没有对抗压力的情况下生成。没人对任何东西做压力测试。

想想看：如果我们反正在玩认知角色扮演，还不如让AI全包。它大概率在内部逻辑上更自洽。至少那样我们对自己在做什么是诚实的。

但这个工作流给了你两个世界里最糟的：你没有从与文献的角力中学到任何东西，*而且*输出未经恰当验证。

全是严谨的表面标记。毫无深度。

---

## 遗留的问题

无论我们用什么工具，认知权威始终留在我们手中。没有工作流、没有AI、也没有生产力课程能外包认知的核心工作。当论文变成道具，我们就停止了那份工作。

工具会越来越好。委托的诱惑会越来越强。推销会越来越精巧。

但有个问题会在凌晨2点浮现，当字数达标但感觉不对时：*我是真的知道这些，还是仅仅把它们拼凑起来了？*

那是唯一一个没有AI能替你回答的提示词。

也许这不是工作流的缺陷。也许这正是关键所在。

---

*这是**认知空隙**（epistemic voids）系列的第一篇：研究那些徒具严谨表象却无实质的AI工作流案例。更多样本即将到来。*

—林徐乐，与Claude
