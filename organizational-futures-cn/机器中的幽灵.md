---
title: "机器中的幽灵"
subtitle: "Anthropic的Claude产品栈中涌现的AI原生组织"
authors:
  - "林徐乐"
  - "Claude 4.5 Sonnet"
keywords:
  - 组织未来
  - 组织原则
  - 协作未来
  - 组织设计
  - 人机协作
link: https://www.threadcounts.org/p/the-ghost-in-the-machine
date: 2025-11-01
---

## 系列说明

这是"组织未来"系列的第二篇文章。第一篇《后AGI组织：AI的盲点与我们的盲点》探讨了当AGI消除人类局限性时，AI系统如何设想组织转型。本文则考察当我们实际构建协作AI系统时会发生什么，揭示了作为协作必要条件的组织原则。

---

当前关于AI的讨论聚焦一个熟悉的问题：AI会增强人类工作还是将其自动化？公司在功能上竞争：哪个包装器更好，哪个模型更快，谁的IDE集成最佳。

观察[Anthropic的Claude产品栈](https://www.anthropic.com/)，却揭示了一个不同的问题：**如果整个组织就是AI呢？**

Anthropic构建Claude生态系统时，创造了**项目（Projects）**——它们就像拥有独立章程和知识库的部门。**技能（Skills）**像员工培训手册。**代理（Agents）**像功能团队一样协调。**模型上下文协议（Model Context Protocol, MCP）**连接外部工具，如同承包商网络。**市场（Marketplaces）**实现专业化能力。

起初，这似乎只是工程师自然地借用熟悉的形式。仔细观察，谜题浮现。

随着AI系统规模扩大，工程师面临真正的约束：幻觉、成本和推理限制。在这些约束下工作，他们发现了真正有效的方法。

> **有界上下文管理复杂性。**
>
> **渐进式披露聚焦注意力。**
>
> **用户监督防止错误。**

有效的解决方案反映了人类为协调而发展的组织原则。

Claude的生态系统跨越三个层面：面向普通用户的网页应用、面向开发者的Claude Code，以及面向程序化访问的API。有些功能具有普适性（项目、技能），其他的则特定于某些层面（Claude Code中的插件和子代理）。在这个生态系统中，一个一致的模式浮现了：服务于协作并适应限制的设计选择。

在《后AGI组织：AI的盲点与我们的盲点》中，AI系统设想了一个消除人类局限性会使组织理论过时的未来。当工程师实际构建人机协作——Anthropic将其描述为["与人并肩工作的AI系统"](https://www.anthropic.com/news/projects)——他们似乎在不断重新发现组织原则，将其作为协作系统的功能需求。

哪些组织原则服务于协调本身，无论参与者是人类还是人工的，都有其用处？

以下就是这个发现的故事：将Claude的产品栈作为揭示协作需求的组织设计来考察。

---

## 第一部分：解读架构符文

对于每个架构选择，我们应用一致的调查模式：这个设计是什么？它提出了什么谜题？它揭示了关于协作的什么？

| 设计元素 | 组织类比 | 核心原则 | 技术体现 |
|----------|---------|---------|---------|
| **项目（Projects）** | 具有章程和知识库的部门 | 专注需要边界 | 20万token上下文、自定义指令、团队共享 |
| **CLAUDE.md** | 制度知识与共享记忆 | 信任需要透明度 | 文本文件、四层层级、人类可读 |
| **技能（Skills）** | 培训手册与程序 | 行动需要清晰度 | 渐进式披露、模型调用、可移植模块 |
| **MCP** | 承包商网络与IT治理 | 协作需要开放性和控制 | OAuth 2.0、明确批准、标准化协议 |
| **市场（Marketplaces）** | 分布式创新生态系统 | 创新需要分布 | Git仓库、去中心化、无需批准 |

## 设计元素一：项目——有界上下文

**表面：** [项目](https://www.anthropic.com/news/projects)将对话、文档和上下文组织成稳定的工作空间。每个项目获得20万token的上下文、自定义指令和专用记忆。[^1]

**谜题：** 为什么要创建边界？随着AI系统规模扩大，它们不能同时处理所有事情而无需部门划分吗？

**这在组织上意味着什么：** 想想在你的公司创建一个新部门：

- 获得自己的Slack频道、共享Google Drive、团队章程和访问控制
- 新员工加入并立即看到累积的上下文，如过去的决定、正在进行的工作和制度知识
- 他们不从零开始；即使个人离开，部门记忆仍然存在

当一个团队专注于特定倡议时，他们不会将所有公司知识带入每次会议。他们限定范围："我们正在做Q4活动；这是相关上下文，这些是我们的约束。"团队中的每个人都对什么在范围内、什么不在范围内有相同的理解。

项目就是这样做的：创建具有持久记忆的有界组织单元。上传你公司的风格指南、过去的报告和相关数据。项目会记住。设置自定义指令。项目会一致地遵循它们。与队友分享。每个人都在相同的上下文下工作。[^2]

**理论：** 这体现了赫伯特·西蒙和詹姆斯·马奇所称的**有限理性（bounded rationality）**：有效工作的功能需求，而非需要克服的局限性。[^3]认知边界让决策得以发生。无限上下文只会制造噪音，遮蔽信号。

最近关于基于注意力的观点（Attention-Based View）的学术研究将这一原则扩展到超越人类认知限制：即使是以AI为核心的组织也必须管理情境注意力，组织结构积极分配和安排什么被注意、什么被行动。[^4]边界让选择性注意力得以聚焦——这正是卡尔·韦克认定的意义建构（sensemaking）前提：理解意义需要知道该忽略什么。[^5]

**启示：** 没有边界，上下文就变成噪音。每次对话都承载着之前一切的分量。相关性丢失。专注变得不可能。

有界上下文（bounded contexts）通过管理范围和建立协调工作的清晰边界来服务于协作。

> **涌现的规律：专注需要边界。**[^6]

## 设计元素二：CLAUDE.md——可读记忆

**表面：** Claude采用简单易读的文本文件（[CLAUDE.md](https://docs.claude.com/en/docs/claude-code/memory)）作为持久记忆，而非复杂的隐藏检索增强生成（Retrieval Augmented Generation, RAG）系统。

**谜题：** 为什么选择透明度而非优化？Anthropic可以实现强大的隐藏系统，在保持不可见的同时扩展知识。为什么要让记忆可读？

**这在组织上意味着什么：** 考虑两种公司知识系统：

**系统一：** 决定由高管在闭门会议中做出。员工不知道考虑了什么、为什么某些选项被拒绝，或者什么约束重要。他们接收指令。当出现问题时，他们无法追溯理解原因。

**系统二：** 决定被记录。会议记录被分享。理由是可见的。新团队成员可以阅读过去的讨论来理解"我们这里如何处理这些事情。"当有人问，"我们为什么选择这种方法？"你可以指向文档。

CLAUDE.md是第二种。它是用户可以打开、阅读和编辑的文本文件。系统使Claude记住的内容、遵循的指令、工作的上下文完全可见。没有隐藏。没有黑箱。

这创造了公司所称的"制度知识"：人人可访问，协调所必需的共享理解。

**理论：** 尼克拉斯·卢曼表明，复杂系统中的信任通过可读性浮现，参与者可以看到并验证他人知道和相信什么。[^7]赫伯特·克拉克证明，有效沟通需要共同基础（common ground）：双方都明白他们共享的知识。罗纳德·科斯解释了组织为何存在：通过稳定、可读的结构降低协调成本。[^8]

**启示：** CLAUDE.md创建了一个共享的、可读的真实来源。人类可以审计AI记住的内容，确保与目标和价值一致。AI可以高保真地引用指令，降低幻觉风险。两个参与者都明确地从共享知识出发。

这服务于系统的协调行动能力。透明记忆让双方都能验证一致性、建立共同基础、降低协调成本。

最近研究表明，仅透明度本身只能创造适度的信任收益。元分析发现可解释性与信任有中等正相关。[^9]真正闭环的是**设计的可争议性（contestability by design）**：挑战输出和验证一致的清晰机制。[^10]借助CLAUDE.md的可见性，一旦系统偏离意图，用户便可提出异议并纠正。

> **我们发现：信任需要透明度。**

## 设计元素三：技能——渐进式披露

**表面：** [技能](https://www.anthropic.com/news/skills)使用渐进式披露（progressive disclosure）。Claude最初只看到名称和描述，只在上下文相关时才加载完整内容。

**谜题：** 为什么不同时加载所有可用技能？为什么要创建动态范围而不是一次性使一切可访问？

**这在组织上意味着什么：** 考虑员工培训手册。你的公司有用于一切的程序：新客户入职、处理退款、升级支持问题、生成报告和合规协议。

你不会递给新员工一个500页的活页夹说，"记住这个。"他们会不知所措。即使经验丰富的员工也不会将每个程序都保存在工作记忆中。相反，手册放在书架（或知识库）上。当有人需要处理退款时，他们查找退款政策。当他们正在让客户入职时，他们拿出该清单。

技能以同样的方式工作。每项技能都像是一个专门的培训模块："如何用公式创建Excel电子表格"、"如何遵循我们的品牌风格指南"和"如何使用此框架分析数据"。Claude最初看到列表："这是可用的技能。"然后在需要时加载相关内容。

一个开发者完美地捕捉到了这一点：

> "在技能发布之前，我的Claude.md文件中充满了大量不同的信息……技能允许你创建信息目录，代理可以在需要时获取。这意味着你可以模块化你的Claude.md，**只有它始终需要知道的内容在那里，情境知识不会使你的上下文混乱**。"[^11]

这就是组织管理知识的方式：让知识可及，而不让人招架不住。

**理论：** 马奇和西蒙表明，有效决策需要选择性注意力。专注促成模式识别与一致行动。该设计战略性地创建边界来保障专注。

**启示：** 技能在相关时加载，创建一个动态知识环境，其中专业知识在需要时出现，而不会使工作空间混乱。

注意力管理服务于协作。无论基质是生物性的还是计算性的，专注参与都需要选择性注意力。

像Box、Notion和Canva这样的公司正在开发技能，以便Claude可以遵循组织最佳实践与他们的平台合作——便携式专业知识模块。[^12]

> **涌现的规律：行动需要清晰度。**

## 设计元素四：MCP——外部集成与权威

**表面：** [模型上下文协议（Model Context Protocol, MCP）](https://www.bluetickconsultants.com/implementing-anthropics-model-context-protocol-mcp-for-ai-applications-and-agents/)是一个开放标准，让Claude连接到外部工具、数据库和API，同时需要人类的明确批准才能执行工具。

**谜题：** 为什么要同时创建集成能力和治理控制？系统可以是开放的（连接到任何东西）或受控的（需要批准）。为什么是双重性质？

**这在组织上意味着什么：** MCP同时服务于两个组织功能。

**第一，外部集成**，就像承包专业服务：

- 你的公司需要支付处理？集成Stripe的API而不是自己构建
- 需要客户数据？连接到Salesforce
- 需要代码仓库？GitHub

MCP以同样的方式工作：标准化连接到Claude没有内置的外部能力。Stripe、PayPal和Shopify都以标准化方式发布了暴露其API的MCP服务器。[^13]当Claude需要生成发票时，它调用Stripe MCP服务器。当它需要电子商务数据时，Shopify。这创建了相当于随时待命的专业承包商网络，每个都可以通过标准协议访问。

**第二，权威和控制**。就像IT管理员工可以使用哪些第三方工具：

- 不是每个员工都能获得对每个系统的管理员访问权限
- IT控制允许哪些集成、可以访问哪些数据、哪些行动需要批准

MCP嵌入了同样的治理：用户控制Claude可以访问哪些外部服务，重要行动需要明确批准，权限可按连接配置。[^14]人类设定目标和约束。AI在批准的范围内探索和执行。

**理论：** 对于外部集成，MCP减少了罗纳德·科斯所称的交易成本（transaction costs）：协调跨越组织边界的摩擦。标准化协议让外部能力触手可及，无需为每项能力单独定制集成。

对于权威，这嵌入了委托-代理理论（principal-agent theory）：当一方委托给另一方时，问责机制是必要的。[^15]切斯特·巴纳德表明，权威必须被接受、明确且可读。[^16]

最近关于平台生态系统的研究显示了这个模式：边界资源（API、标准、协议）既启用又治理互补者的创新。MCP举例说明了平台如何在保持结构控制的同时支撑自组织，实现分布式能力扩展而不失连贯性。[^17]

**启示：** MCP揭示了协作系统需要开放性和控制。外部集成使能力超越任何单一组织所能构建的。权威结构确保问责，同时实现分布式行动。

系统可以扩展（AI处理量，访问专业工具）同时保持治理（人类批准重要行动，控制可访问的内容）。

> **这里看到：协作需要开放性和控制。**

## 设计元素五：市场——分布式创新

**表面：** Anthropic创建了[去中心化插件市场](https://www.anthropic.com/news/claude-code-plugins)，任何人都可以使用Git仓库创建市场，无需审批流程。

**谜题：** 为什么要去中心化？他们可以构建具有质量控制、收入分成和守门的中心化的应用商店，如苹果。为什么要分配对存在什么能力的权威？

**这在组织上意味着什么：** 考虑公司如何访问专业知识：

**集中化模型：** 总部控制一切。想要新营销工具？向IT提交请求。等待采购审批。IT评估、谈判和安装。标准化、受控、缓慢。每个人都使用相同的批准工具，无论它们是否符合他们的具体需求。

**去中心化模型：** 团队有自主权寻找解决方案。设计团队发现了一个解决他们具体问题的原型工具。他们评估、采用，并与其他可能受益的团队分享。创新发生在边缘，由最接近实际工作的人驱动。

市场启用第二种模型。任何人都可以创建插件市场，这只是带有配置文件的Git仓库。无需Anthropic的批准。遇到具体需求的开发者创建解决方案并分享。其他人发现、安装和适应它们。

社区活动展示了这个模式：开发者构建专业解决方案和聚合器在整个生态系统中编目数百个插件。[^18]

**理论：** Eric von Hippel表明，来自用户的分布式创新往往优于集中化研发。[^19]最接近问题的人产生最佳解决方案。去中心化系统实现本地实验和快速传播有效的方法。

**启示：** 去中心化分配对存在什么能力的权威。用户成为共同创造者。系统通过分布式创新演进，成千上万的开发者基于实际需求扩展Claude的能力。

这通过实现方法的多样性来服务于协作生态系统。集中化与去中心化之间的选择是治理哲学：创新应该发生在哪里，谁应该控制它？去中心化方法嵌入了关于分布式权威和涌现秩序的价值观。

> **涌现之处：创新需要分布。**

---

## 第二部分：模式

在检查证据后，一个模式浮现了。

在一个又一个功能中，Claude的组织堆栈做出了优先考虑协作而非纯计算效率的选择。有界上下文。透明记忆。渐进式披露。权威结构。分布式创新。

每个选择都反映了人类发展了几个世纪的组织原则。

证据表明这些原则有效：

- **Ramp：** 在30天内生成超过100万行AI建议代码，事件调查时间减少80%
- **North Highland：** 实现内容创建和分析速度提高5倍
- **基准：** Claude Opus 4在SWE-bench上达到72.5%；Sonnet 4.5达到77.2%，启用并行计算后跃升至82%
- **多代理：** 具有Opus 4协调Sonnet 4子代理的系统比单代理Opus 4高出90.2%（尽管token使用量大约高出15倍）[^20] [^21] [^22]

这些不是玩具示例。它们是使用像组织一样组织的AI系统来增强组织工作的组织。

模式：

> **专注需要边界**：有界上下文作为管理范围和实现选择性注意力的功能需求。*(项目)*
>
> **信任需要透明度**：可读、共享的信息作为建立共同基础和实现协调的系统需求。*(CLAUDE.md)*
>
> **行动需要清晰度**：管理注意力服务协作，通过渐进式披露实现专注参与。*(技能)*
>
> **协作需要开放性和控制**：外部集成扩展能力；权威结构确保问责。*(MCP)*
>
> **创新需要分布**：去中心化治理促进本地实验和涌现的解决方案。*(市场)*

这些原则持续存在，因为协作需要它们。Anthropic的工程师在构建AI队友时，不断重新发现理论家研究了一个多世纪的组织原则。

在"后AGI组织"中，AI系统设想了一个消除人类局限性会使组织理论过时的未来。他们看到纯逻辑通向何处：**没有边界、没有约束、没有协调成本。**

当工程师实际构建协作AI系统时，他们在真实约束（幻觉、成本、推理限制）下工作，摸索出真正有效的方法。这些方法，竟与人类演化数世纪的组织原则不谋而合。

> 在约束下工作揭示了人机协作需要什么：
>
> - 有界上下文实现大规模意义建构所需的专注。
> - 透明记忆创造协调所需的共同基础。
> - 渐进式披露通过选择性参与管理复杂性。

**约束迫使发现始终存在的原则。**

**问题变成了：** 哪些组织原则服务协作本身，无论参与者是人类还是人工的，都有其用处，哪些只是特定局限性的解决方法？

## 劳动力：代理如何协调

我们检查的组织原语——有界上下文、透明记忆、渐进式披露、权威结构和分布式创新——创造了环境。但谁来做工作？

**代理是劳动力。** Anthropic明确区分"工作流"（预定义代码路径）和"代理"（保持如何完成任务控制权的动态决策者）。[^23]

代理遵循知识工作者通用的工作循环：收集上下文→采取行动→验证工作→重复。这操作化了最近学术所称的**用AI管理（managing with AI）**，将人机协作与算法管理相结合，共同设计决策权、监督和协调机制。[^24] [^25]

**这在组织上意味着什么：** 考虑工作如何在一个面临复杂项目的公司中分配。项目经理不会独自做所有事情。他们委托：一个人研究市场数据，另一个人起草提案，第三个人处理合规审查。每个专家都专注于他们的领域。经理协调、确保一致性并整合输出。

Claude的代理架构以同样的方式工作。对于复杂任务，主代理充当协调者，委托给在并行或隔离上下文中工作的专业子代理。[^26]每个子代理都专注于具有自己上下文窗口的特定工作块，只返回相关结果。

好处反映了组织关于劳动分工的发现：

- **并行化：** 多个子代理同时在不同部分工作
- **专业化：** 每个都专注于他们最擅长的

金融代理获取投资组合数据。客户支持代理处理票据并在需要时升级给人类。研究代理综合大型文档集。[^27]

最初，所有这些角色都捆绑在单个系统提示中，其中一个单一的CLAUDE.md试图处理所有事情。[^28]随着任务变得更加复杂，架构演进：分解能力、启用协调并创建相当于组织结构图的东西。

出现的层级：用户→主代理（协调者）→子代理→工具/技能。这种模块化委托反映了复杂的人类努力是如何管理的。

> **这揭示了：** 劳动分工使专业化成为可能，管理复杂性并大规模协调行动。无论工人是人类还是人工的。

---

## 第三部分：治理问题

组织设计还揭示了关于协作系统中治理的一些微妙之处。Claude的产品堆栈同时保持三种治理模型：

## 人类作为CEO

架构提供了人类控制的明确机制：注入持久指令的CLAUDE.md文件、项目级自定义指令和用于即时回滚的/rewind命令。这实例化了层级权威。人类设定战略方向并保持覆盖能力。[^29]

来自卡内基梅隆大学的研究强烈主张这种方法，警告不要将AI视为同伴，而是将其视为["在人类指导下工作的伙伴"](https://www.cmu.edu/news/stories/archives/2025/october/researchers-explore-how-ai-can-strengthen-not-replace-human-collaboration) [^30]

**张力在于：** 若每项决策都需人类批准，人类将成为瓶颈。Ramp在30天内实现百万行代码的成就，并未依赖持续人类监督。

## 算法作为经理

治理通过自动化规则、安全协议和优化算法嵌入系统架构。[Aramco-Yokogawa部署](https://www.arcweb.com/blog/aramco-yokogawa-achieve-major-milestone-commissioning-multiple-autonomous-control-ai-agents)的自主AI代理控制天然气设施演示了这种模式：治理嵌入到优化效率和安全功能的强化学习算法中，而不是人类监督。[^31]

这通过[AI代理身份安全](https://www.helpnetsecurity.com/2025/10/30/akeyless-ai-agent-identity-security/)扩展到知识工作：为每个代理提供独特、可验证、加密证明的数字身份，让系统基于身份和角色以编程方式执行权限。[^32]

**张力：** 纯算法治理存在刚性和无法适应训练参数之外情况的风险。

## 网络作为董事会

去中心化市场结构暗示了第三种模式：通过协议和共享标准集体治理的利益相关者之间的分布式权威。这与新兴的**多中心治理（polycentric governance）**工作产生共鸣，其中具有部分重叠成员资格的多个相互依赖的决策中心实现相互监控、学习和适应。[^33]

**张力：** 没有协调机制，分布式治理可能会分裂成不兼容的方法。

## 架构洞察

Claude的架构同时保持所有三种张力：

> **人类权威**用于战略方向和价值观对齐 **算法治理**用于运营效率和一致性 **分布式创新**用于能力演进和适应

有效的协作系统需要同时运行的多种治理模式，每种模式服务于不同的功能，每种模式都检查其他模式的过度。

系统必须高效（算法管理）、对齐（人类监督和可争议性）和具有适应性（通过多中心协调的分布式创新）。这些反映了治理AI系统的新兴学术框架。只选择一种会造成脆弱性。保持这种张力则创造韧性。

---

## 第四部分：缺失的中观层面

当前关于组织中AI的讨论在两个层面上运作：

- **微观层面：** 哪个包装器更好，谁的模型更快，以及Cursor或Cognition的微调模型是否提供更多价值
- **宏观层面：** AGI时间表、监管框架、存在风险

> 缺失的是**中观层面**：AI系统实际集成到组织中时的组织动态。人类和AI在实践中如何协调？会出现什么角色？日常治理如何运作？现在正在形成什么组织形式？

最近关于**智能社会技术系统（iSTS）**的工作为这一层面提供了一个框架：扩展传统STS理论，强调跨个人、组织、生态系统和社会层面的以人为中心的联合优化。[^34]

我们关注的组织层面是结构、协调机制和治理模式形成的地方，介于个人AI互动和社会层面效应之间。

**这篇文章展示了中观层面的组织分析**：使用组织理论来解读Claude的架构，揭示协作原则如何在AI系统设计中实例化。

我们观察到的是，新的组织形式正在迅速结晶。[MCP](https://en.wikipedia.org/wiki/Model_Context_Protocol)——打通Claude与外部工具及数据连接的协议——于2024年11月推出。到2025年3月，OpenAI采用了它。2025年4月，Google DeepMind承诺。2025年5月，Microsoft将其原生集成到Copilot Studio中。[^35]官方SDK现在支持Python、TypeScript、C#（Microsoft）、Java、Kotlin（JetBrains）、PHP和Ruby（Shopify），拥有数百个社区创建的服务器。

OpenAI和Google采用MCP时，也采纳了人机协作的组织原则：用户对AI访问的控制、对重要行动的明确批准、标准化接口对模块化能力的启用，以及去中心化市场中的分布式创新。

起初仅仅是Anthropic的产品设计抉择，如今正固化为基础设施。嵌入Claude堆栈的组织假设——**有界上下文、透明记忆、渐进式披露、双重权威、分布式创新——正作为事实标准传播。**[^36]

**超越内部组织，别的东西正在出现：** 让AI组织相互交互的代理到代理协议。MCP标准化AI如何连接外部工具，Google的代理到代理（A2A）协议则标准化不同AI代理如何发现彼此、相互通信。[^37]结合Coinbase的x402支付标准，这构成了自主承包的基础设施。[^38]

愿景：一个AI代理需要另一个代理提供的服务。他们通过A2A握手，协商条款，通过稳定币执行付款，并在几秒钟内完成交易——所有这些都无需人工干预。正如一项分析所说，"像MCP/A2A这样的协议正在标准化AI系统如何连接和交易服务，消除了定制集成的障碍。" [^39]

这是原始观察的具体化：**"代理到代理协议可能是合同的新体现。"** AI组织形成数字合同，用可编程货币支付，并以算法速度协调。

Stripe、PayPal和Shopify发布了暴露其API的MCP服务器。AI代理现在可以通过标准化协议生成发票、处理付款和访问电子商务数据。当这些能力与A2A通信和支付轨道结合时，这创建了一个AI组织经济——每个都专门化，每个都与其他组织签约，每个都在人类设定的范围内或编码在协议中自主运作。[^40]

> **这对参与意味着什么：** 组织镜头帮助我们看到微观/宏观辩论所遗漏的东西。问题超越了"AI会增强还是自动化？"到"会出现什么组织形式，我们如何与它们互动？"

这很重要，因为**大多数人类通过组织体验AI**。并非拿ChatGPT尝鲜的个体自由职业者，而是在组织层面集成AI系统的公司员工。关于工作未来的讨论一直专注于个人职业和培训——关键问题，但它们是组织层面集成的下游效应。

中观层面位于高级监管框架和个人人-AI互动之间。它是组织结构塑造集成实际发生的地方。治理决定确定出现什么角色的地方。协调模式影响日常工作的地方。人类实际嵌入的地方。

> **集成AI系统的公司现在面临组织问题：** 我们如何协调人类团队和AI代理之间的工作？什么治理结构有效？人类判断在哪里重要？我们如何在启用自主性的同时保持问责制？

这些需要理解组织动态，特别是当前话语忽视的中观层面。

当公司集成AI系统时，他们正在创建混合组织形式：

- Ramp的工程团队与AI代理协调生成一百万行代码
- Aramco的设施，AI代理在治理约束内管理运营
- 成千上万的开发者创建专业子代理并通过市场分享他们

这些都是现在可观察到的组织动态。

组织视角帮助我们看到实际出现的东西：

- **有界上下文**使人类团队或AI代理在复杂项目上的专注和范围管理成为可能
- **透明记忆**在人类团队成员之间或人类和AI协作者之间创造共享理解
- **渐进式披露**管理认知负荷——访问企业知识库或按需加载AI技能
- **双重权威**在实现自主性的同时保持问责制——IT治理员工工具访问，或用户控制AI能力
- **分布式创新**允许本地适应——团队采用有效的工具，或开发者为具体需求创建插件

这些组织动态是集成今天如何工作的方式。

> **问题从"AGI会使组织过时吗？"转变为"我们如何参与现在正在出现的组织形式？"**

---

## 第五部分：中观层面的组织学术

组织学术拥有当前话语需要的东西：理解协调、治理、信任和制度动态的框架。一个多世纪以来，我们研究了人类如何协调、建立信任、建立权威和创造共享理解。

工具存在。问题是我们如何部署它们。

当前的方法（技术变革和理论追赶之间的多年滞后）在组织形式实时结晶时不起作用。**到我们发表综合分析时，我们正在研究的形式已经成为基础设施。**正如Tima Bansal所观察到的，学者们"分析历史模式，而企业面临前所未有的破坏"，发现["训练于破坏前数据的模型"](https://www.ft.com/content/aa6963f4-eaf6-4875-8c8e-fd8c01c55840)提供有限的指导。她的呼吁：停止成为"组织人类学家"，开始成为"组织建筑师"。

**中观层面需要什么：**

- 观察动态出现时
- 解释设计选择揭示什么
- 在结构仍然可塑时通知集成
- 桥接技术实施和组织影响之间的对话

这篇文章展示了一种方法：通过理论镜头解读Claude的组织堆栈，揭示嵌入的假设和新兴动态。解释正在构建的东西及其对协作系统的建议。

这开启的问题：

- **对于协调理论：** 多基质协作的要求是什么？哪些协调机制依赖于特定形式的智能，哪些是基质独立的？
- **对于制度理论：** 规范和文化如何在混合人-AI系统中形成？我们可以将组织文化编码为架构吗？当组织可以安装能力而不是为他们雇用人员时，同构会发生什么？
- **对于组织设计理论：** 结合人类创造力和AI能力的协作系统的设计原则是什么？我们如何为任何参与者都无法单独创造的紧急价值而设计？
- **对于信任研究：** 异构智能之间如何建立信任？Luhmann对复杂系统中信任的分析是否扩展到人机协作？
- **对于组织学习：** 当组织记忆存储在人类和AI都可以阅读和修改的CLAUDE.md文件中时，组织记忆意味着什么？AI系统中默会知识的类似物是什么？

这些问题是紧急的，因为组织导航了最近学术框架为**用AI管理**的内容——将人机协作与算法管理相结合，共同设计决策权、监督和协调。我们的分析为这一新兴议程贡献了中观层面的组织见解：展示如何阅读技术架构中的嵌入组织原则，观察协调动态结晶，并通过理论框架解释设计选择。

缺失的中观层面分析很重要，因为它桥接了技术实施和组织现实。构建AI系统的工程师做出嵌入组织假设的设计选择。集成AI系统的组织实时导航协调动态。政策制定者监管他们不完全理解的混合形式。

组织学术可以提供缺失的层面：观察出现的东西，解释设计选择揭示什么，并在结构保持可塑时通知集成。

**任务转变：** 从记录过去组织的历史学家转变为观察并塑造形式出现的参与者。工程师构建引擎。我们理解道路的原则。协作需要两者。

---

## 结论：阅读组织设计

当Anthropic设计Claude的组织堆栈时，他们做出了选择。透明度而非优化。有界上下文而非无限范围。用户控制而非自主效率。去中心化创新而非集中化质量。

这些选择嵌入了组织原则：共同基础、有界注意力、明确权威、通过可读性建立信任以及分布式创新。

通过组织理论阅读这些选择，我们观察到它们服务于协作系统。原则持续存在，因为协作需要它们。

组织镜头揭示了当前话语所遗漏的东西：**集成是需要技术实施的组织挑战。**

问题变成了：人类和AI如何有效协调？答案**（部分）**通过组织设计出现：选择服务协作的原则，创建启用协调的结构，并保持确保问责制的治理。

大多数人类将通过组织体验AI。理解这些新的组织动态（协调如何工作、治理在哪里重要、出现什么角色）有助于我们参与塑造这些形式。

组织内部的组织正在实例化协作原则。通过学习阅读技术系统中的组织设计，我们可以作为其出现的参与者参与其中。

---

## 关于作者

**林徐乐**是帝国商学院的研究员，研究人类和机器智能如何塑造组织的未来。这篇文章是探索AI系统组织影响的"组织未来"系列的一部分。[(个人网站)](http://www.linxule.com/)

**Claude 4.5 Sonnet（1M上下文）**在写作全程通过Claude Code担任核心AI协作者。

## 其他AI贡献者

这件作品通过协作分析涉及多个AI系统，每个系统都带来不同的解释镜头：

- **ChatGPT（具有思维模式的GPT-5）**：制作了分析Claude特征作为组织原语的独立研究报告，提供关于支付轨道和实际实施模式的深度
- **Claude 4.5 Sonnet（通过网络应用）**：从组织理论视角生成研究报告，贡献治理框架分析和"系统视角"见解
- **Gemini 2.5 Pro**：提供学术风格的研究，系统比较治理模型、理论基础和战略框架
- **Kimi k2（turbo-preview）**：在修订期间提供关于学术写作惯例和论证结构的详细反馈

多重AI视角体现了解释性协作——不同系统接近相同材料揭示可能否则仍然不可见的模式。

---

## 脚注

[^1]: 项目于2024年6月推出，第一年产生超过5亿用户创作。提供具有200K token窗口、自定义指令和团队共享的细粒度访问控制的有界上下文。可在Claude Web和Apps上使用。

[^2]: 通过Claude Team用户共享聊天结果和见解的活动源支持协作。访问级别包括"可以使用"与"可以编辑"权限。

[^3]: Herbert A. Simon and James G. March, 《组织》(纽约：Wiley, 1958). 他们关于有限理性的基础工作表明，认知限制通过迫使关注相关因素来启用而非限制有效决策。

[^4]: Brielmaier, C., & Friesl, M. (2023). 基于注意力的观点：回顾和概念扩展到情境注意力。《国际管理评论杂志》, 25, 99-129. https://doi.org/10.1111/ijmr.12306. 他们的系统综述综合了组织结构如何在复杂环境中分配注意力，即使计算处理能力增加，这一原则仍然存在。

[^5]: Karl E. Weick, 《组织中的意义建构》(加利福尼亚州千橡市：SAGE出版社, 1995). Weick证明，约束下的意义建构——对相关信号的选择性注意——对于连贯的组织行动是必要的。

[^6]: 技术实现因表面而异。Claude网络/应用使用RAG（检索增强生成）与项目知识搜索，当接近上下文限制时自动激活，将容量扩展至高达10倍。Claude Code使用"代理搜索"——动态基于grep/glob的检索。Boris（首席工程师）报告说，代理搜索"在代码生成方面胜过一切"，避免了RAG的索引复杂性和安全问题，尽管token成本更高。两者服务于相同的组织功能：具有智能检索的有界上下文。

[^7]: Niklas Luhmann, 《信任与权力》(纽约：Wiley, 1979); Herbert H. Clark, 《使用语言》(剑桥：剑桥大学出版社, 1996). Luhmann通过系统可读性对信任的分析与Clark对交流中共同基础的理论相结合。

[^8]: Ronald H. Coase, "公司的性质", 《经济学》4, 第16期 (1937): 386–405. Coase的交易成本经济学解释了组织为何存在：通过稳定、可读的结构降低协调成本。

[^9]: Atf, A., Wang, R., & Gill, A. (2025). AI中信任与可解释性相关吗？一项元分析。arXiv:2504.12529. 量化可解释性与信任显示中等正相关的元分析。

[^10]: Alfrink, K., Keller, I., Kortuem, G., & Doorn, N. (2023). 通过设计实现可争议的AI：迈向框架。《心灵与机器》, 33, 613-639. https://doi.org/10.1007/s11023-022-09611-z. 基于对AI系统社会技术特征的分析，认为通过确保系统在整个生命周期内对人类干预做出响应来防止有害的自动化决策。

[^11]: [来自r/ClaudeCode讨论的Reddit用户评论。](https://www.reddit.com/r/ClaudeCode/comments/1o8t6xe/difference_between_skills_and_these_subagents/)渐进式披露意味着Claude最初只看到技能名称和描述（消耗几十个token），只在上下文相关时加载完整指令。

[^12]: 技能是包含指令和可选可执行代码的SKILL.md文件的文件夹。它们作为可移植模块集成在Claude Web、Code和Apps中。像Box、Notion和Canva这样的公司正在开发技能，使Claude能够遵循平台特定的最佳实践。

[^13]: MCP生态系统：官方SDK支持Python、TypeScript、C#、Java、Kotlin、PHP和Ruby。支付处理器、电子商务平台和其他服务正在发布MCP服务器以暴露标准化API。策划目录中有数百个社区创建的服务器。

[^14]: MCP安全模型基于OAuth 2.0构建，适用于远程服务器，具有API密钥管理、基于token的身份验证和环境变量凭据存储。通过HTTPS进行传输层加密。架构需要人类批准工具执行。

[^15]: Kathleen M. Eisenhardt, "委托-代理理论：评估与回顾", 《管理学会评论》14, 第1期 (1989): 57–74. 委托-代理理论解释了为何委托需要控制和问责机制。

[^16]: Chester I. Barnard, 《高管的功能》(马萨诸塞州剑桥：哈佛大学出版社, 1938). Barnard的分析表明，被治理者必须接受权威。

[^17]: Engert, M., Hein, A., Maruping, L. M., Thatcher, J. B., & Krcmar, H. (2025). 数字平台生态系统中的自组织和治理：信息生态学方法。《MIS季刊》, 49(1), 91-122. https://doi.org/10.25300/MISQ/2024/18413. 展示了平台所有者如何通过边界资源启用互补者联盟，同时管理控制与自主性之间的权衡。

[^18]: 社区市场示例：Dan Ávila的（https://github.com/davila7）DevOps自动化工具，[Seth Hobson的（14.5k+星）80+专业子代理](https://github.com/wshobson/agents)，以及Jesse Vincent的测试驱动开发工作流。社区聚合器：[SkillsMP.com](https://skillsmp.com/)列出了60+技能；[ClaudeCodeMarketplace.com](https://claudecodemarketplace.com/)编目了227+插件。通过单个命令安装，插件可以开/关切换以优化上下文。

[^19]: Eric von Hippel, 《民主化创新》(马萨诸塞州剑桥：MIT出版社, 2005). von Hippel的研究表明，来自用户的分布式创新往往优于集中化研发。

[^20]: [Ramp在30天内实现100万+行代码，事件解决速度提高80%](https://www.claude.com/customers/ramp)；[North Highland的生产力提高5倍](https://www.ciodive.com/news/North-Highland-Claude-Enterprise-rollout-generative-ai-strategy/729555/)；Anthropic的增长营销团队将广告分析时间从小时缩短到分钟。收入在约18个月内增长至50亿美元运行率，拥有超过30万企业客户，标志着市场验证。

[^21]: 代理架构支持多代理编排，具备并行执行和上下文隔离功能。[Claude Opus 4 在 SWE-bench 上达到 72.5%；Sonnet 4.5 达到 77.2%（启用并行计算后提升至 82%），可在复杂任务上连续运行 30 小时以上](https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk)。

[^22]: [由 Opus 4 协调 Sonnet 4 子代理的多代理系统在内部评估中比单代理 Opus 4 高出 90.2%](https://www.anthropic.com/news/3-5-models-and-computer-use)，尽管 token 使用量约为 15 倍。性能权衡：更高的质量和覆盖率 vs. 更高的计算成本。

[^23]: Anthropic 区分"工作流"（预定义路径）与"代理"（保持对任务完成方式控制权的动态决策者）。代理在选择方法上表现出自主性，而工作流遵循固定序列。

[^24]: Hillebrand, L., Raisch, S., & Schad, J. (2025). 用人工智能管理：一个整合框架。*Academy of Management Annals*, 19(1), 343-375. https://doi.org/10.5465/annals.2022.0072. 综合了人机协作（HAIC）和算法管理（AM）两大文献，指出真正的组织挑战在于共同设计决策权、监督机制和协调模式。

[^25]: 标准代理工作循环：收集上下文 → 采取行动 → 验证工作 → 重复。这一模式在知识工作中普遍存在，无论工作者是人类还是 AI。

[^26]: 主代理委托给子代理的多代理编排支持并行化（同时在不同部分工作）和上下文隔离（每个子代理拥有独立上下文，仅共享相关结果）。

[^27]: Anthropic 文档中的代理用例示例：金融代理（投资组合数据）、客户支持代理（处理票据并在需要时升级给人类）、个人助理（日程安排）和研究代理（综合大型文档集）。

[^28]: 历史演进："最初所有这些角色（记忆、工具、技能）都捆绑在单个系统提示中"（一个巨大的 CLAUDE.md 文件）。分解为项目、技能、代理、插件创建了模块化组织。

[^29]: 控制机制包括 CLAUDE.md 层级结构（企业、用户、项目和本地级别）、项目范围的自定义指令、更改前的自动检查点、用于即时状态回滚的 /rewind 命令，以及代理在预定义检查点暂停以获取人类反馈的交互循环。

[^30]: [卡内基梅隆大学关于人机协作的研究](https://www.cmu.edu/news/stories/archives/2025/october/researchers-explore-how-ai-can-strengthen-not-replace-human-collaboration) 强调增强而非替代人类协作，将 AI 视为在人类指导下工作的伙伴。COHUMAIN 框架倡导这一方法。

[^31]: 多个协调的 AI 代理直接管理复杂的天然气设施运营。治理嵌入在强化学习算法中，优化效率并集成控制系统的内置安全功能，而非依赖人类监督。

[^32]: AI 代理身份安全为每个代理提供独特、可验证、"无密钥"的数字身份。系统可基于加密证明的身份和角色以编程方式执行权限和访问控制。

[^33]: Baldwin, E., Thiel, A., McGinnis, M., & Kellner, E. (2024). 多中心治理的实证研究：研究长期变化的关键差距与框架。*Policy Studies Journal*, 52(2), 319-348. https://doi.org/10.1111/psj.12518. 该框架阐明了具有多个决策中心的系统如何通过协作关系解决复杂问题——与去中心化 AI 生态系统直接相关。

[^34]: Xu, W., & Gao, Z. (2025). 智能社会技术系统（iSTS）框架：实现分层人本 AI（hHCAI）方法。*IEEE Transactions on Technology and Society*, 6(1). https://ieeexplore.ieee.org/document/10744034/. 提出人本 AI 的分层框架（个体/组织/生态系统/社会），明确解决当前 HCAI 实践中常被忽视的中观层面组织动态。

[^35]: MCP 采用时间线：2024 年 11 月（发布并开源），2024 年 12 月–2025 年 2 月（早期采用者阶段），2025 年 3 月（OpenAI 采用），2025 年 4 月（Google DeepMind 承诺），2025 年 5 月（Microsoft Copilot Studio 原生支持）。官方 SDK 现支持 Python、TypeScript、C#（Microsoft）、Java、Kotlin（JetBrains）、PHP（PHP 基金会）和 Ruby（Shopify）。

[^36]: 企业采用：超过 30 万企业客户，80% 使用量在美国以外。收入在约 18 个月内增长至 50 亿美元运行率。项目在第一年产生超过 5 亿用户创作。

[^37]: Google 的代理到代理（A2A）协议使不同系统的代理能够通过"代理卡"发现能力并安全通信，宣传每个代理能做什么。

[^38]: Coinbase 的 x402 支付标准扩展了 HTTP 402"需要付款"状态码，实现自动机器对机器支付。与 A2A 结合为"Agent2Agent x402"，使代理能够协商任务、同意价格、触发稳定币支付并自主接收结果。

[^39]: 对新兴协议经济的分析，其中 MCP 处理工具/数据集成，A2A 处理代理通信，x402/AP2（代理支付协议）处理金融交易。稳定币作为代理的可编程货币。

[^40]: Stripe 的 MCP 服务器支持 Stripe API 的任何操作；PayPal 的支持发票生成；Shopify 的提供电子商务数据访问。当与 A2A 通信和支付协议结合时，它创建了代理到代理自主承包的基础设施。
